{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8859cdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\PythonVirtualEnvironments\\hyperlib\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from hyperlib.manifold.lorentz import Lorentz\n",
    "from hyperlib.manifold.poincare import Poincare\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from spektral.data import SingleLoader\n",
    "from spektral.datasets.citation import Citation\n",
    "from spektral.transforms import LayerPreprocess\n",
    "from spektral.layers import GCNConv\n",
    "from spektral.models.gcn import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4176c3c-83c2-45f6-af9a-e240973fc729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7438dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d654d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperlib.nn.layers.linear import ActivationHyperbolic, LinearHyperbolic\n",
    "from hyperlib.nn.layers.graph import HGCLayer, HyperbolicAggregation, HGCNLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f1fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ebe4a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\PythonVirtualEnvironments\\hyperlib\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ConvHyperbolic(16, self.manifold, self.c0, self.c1, activation=\"relu\")\n",
    "hgc_layer = HGCLayer(100, Poincare(), 0.4, \"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9421213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperlib.utils.data_utils import load_data, load_data_lp, mask_edges, process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22811d8",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5fa8225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PythonVirtualEnvironments\\hyperlib\\lib\\site-packages\\scipy\\sparse\\_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "from spektral.datasets import citation\n",
    "\n",
    "dataset = citation.Cora()\n",
    "graph = dataset[0]\n",
    "\n",
    "# Node features\n",
    "X = graph.x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bb7fe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.n_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e4ba242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse array of type '<class 'numpy.float32'>'\n",
       "\twith 10556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b32af73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 1433)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "949e5d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Nalex\\Playgrounds\\HyperbolicPackage\\branch\\hyperlib\\hyperlib\\utils\\data_utils.py:67: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:620.)\n",
      "  return torch.sparse.FloatTensor(indices, values, shape)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3664290, 3696)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data_lp(\"cora\", True, \"resources\\\\data\\\\hgcn\\\\cora\")\n",
    "\n",
    "val_prop = 0.1\n",
    "test_prop = 0.2\n",
    "split_seed = 42\n",
    "normalize_adj = False\n",
    "normalize_feats = False\n",
    "\n",
    "adj = data['adj_train']\n",
    "\n",
    "adj_train, train_edges, train_edges_false, val_edges, val_edges_false, test_edges, test_edges_false = mask_edges(\n",
    "        adj, val_prop, test_prop, split_seed\n",
    ")\n",
    "data['adj_train'] = adj_train\n",
    "data['train_edges'], data['train_edges_false'] = train_edges, train_edges_false\n",
    "data['val_edges'], data['val_edges_false'] = val_edges, val_edges_false\n",
    "data['test_edges'], data['test_edges_false'] = test_edges, test_edges_false\n",
    "    \n",
    "data['adj_train_norm'], data['features'] = process(\n",
    "    data['adj_train'], data['features'], normalize_adj, normalize_feats\n",
    ")\n",
    "\n",
    "\n",
    "data.keys()\n",
    "\n",
    "data[\"adj_train\"]\n",
    "\n",
    "data['adj_train_norm']\n",
    "\n",
    "data[\"features\"]\n",
    "\n",
    "data['features']\n",
    "\n",
    "n_nodes, feat_dim = data['features'].shape\n",
    "\n",
    "n_nodes, feat_dim\n",
    "\n",
    "nb_false_edges = len(data['train_edges_false'])\n",
    "nb_edges = len(data['train_edges'])\n",
    "nb_false_edges, nb_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e564eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperlib.nn.layers.linear.LinearHyperbolic at 0x1eb18106620>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearHyperbolic(data['features'][1].shape, Lorentz(), 1.0, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dea472bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperlib.nn.layers.linear.LinearHyperbolic at 0x1eb18136860>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearHyperbolic(1433, Lorentz(), 1.0, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ee576b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b629088",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76fd2050",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgcn = HGCNLP(1433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02e01032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse array of type '<class 'numpy.float32'>'\n",
       "\twith 10556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad9c87d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)\n",
    "\n",
    "graph_tf = convert_sparse_matrix_to_sparse_tensor(graph.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80b2593f-6aee-4810-af6f-392a9812a36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse array of type '<class 'numpy.float32'>'\n",
       "\twith 10556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e3074ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "x shape empmap0 (2708, 1433)\n",
      "HGCLayer x shape (2708, 1433)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'linear_hyperbolic_3' (type LinearHyperbolic).\n\n{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [2708,1] vs. shape[1] = [1,2708,1432] [Op:ConcatV2] name: concat\n\nCall arguments received by layer 'linear_hyperbolic_3' (type LinearHyperbolic):\n  • inputs=tf.Tensor(shape=(2708, 1433), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mhgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_tf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#grads = tape.gradient(loss_value, self.embedding.trainable_weights)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#optimizer.apply_gradients(zip(grads, self.embedding.trainable_weights))\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#if step % 100 == 0:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#    log.info(\"Training loss (for one batch) at step %d: %.4f\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m#        % (step, float(loss_value)))\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PythonVirtualEnvironments\\hyperlib\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\Nalex\\Playgrounds\\HyperbolicPackage\\branch\\hyperlib\\hyperlib\\nn\\layers\\graph.py:76\u001b[0m, in \u001b[0;36mHGCNLP.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     72\u001b[0m x_hyp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanifold\u001b[38;5;241m.\u001b[39mproj(x_hyp, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc1)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Map euclidean features to Hyperbolic space\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m#x = self.manifold.expmap0(x, c=self.c_map)\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Stack multiple hyperbolic graph convolution layers\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m x, adj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv0\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m#x, adj = self.conv1((x, adj))\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m#x, adj = self.conv2((x, adj))\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m#         regularization objective in node classification tasks, to encourage embeddings at the last layer to\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m#         preserve the graph structure\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Nalex\\Playgrounds\\HyperbolicPackage\\branch\\hyperlib\\hyperlib\\nn\\layers\\graph.py:42\u001b[0m, in \u001b[0;36mHGCLayer.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# x = self.manifold.logmap0(x, c=self.c)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Step 2 (attention-based neighborhood aggregation)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHGCLayer x shape\u001b[39m\u001b[38;5;124m'\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregation_layer((x, adj))\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Step 3 (non-linear activation with different curvatures)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Nalex\\Playgrounds\\HyperbolicPackage\\branch\\hyperlib\\hyperlib\\nn\\layers\\linear.py:42\u001b[0m, in \u001b[0;36mLinearHyperbolic.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# TODO: remove casting and instead recommend setting default tfd values to float64\u001b[39;00m\n\u001b[0;32m     41\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(inputs, tf\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m---> 42\u001b[0m mv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanifold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmobius_matvec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanifold\u001b[38;5;241m.\u001b[39mproj(mv, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinearHyperbolic x shape\u001b[39m\u001b[38;5;124m'\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mD:\\Nalex\\Playgrounds\\HyperbolicPackage\\branch\\hyperlib\\hyperlib\\manifold\\lorentz.py:147\u001b[0m, in \u001b[0;36mLorentz.mobius_matvec\u001b[1;34m(self, m, x, c)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmobius_matvec\u001b[39m(\u001b[38;5;28mself\u001b[39m, m, x, c):\n\u001b[1;32m--> 147\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogmap0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m     mu \u001b[38;5;241m=\u001b[39m u \u001b[38;5;241m@\u001b[39m m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpmap0(mu, c)\n",
      "File \u001b[1;32mD:\\Nalex\\Playgrounds\\HyperbolicPackage\\branch\\hyperlib\\hyperlib\\manifold\\lorentz.py:139\u001b[0m, in \u001b[0;36mLorentz.logmap0\u001b[1;34m(self, x, c)\u001b[0m\n\u001b[0;32m    136\u001b[0m res \u001b[38;5;241m=\u001b[39m sqrtK \u001b[38;5;241m*\u001b[39m arcosh(theta) \u001b[38;5;241m*\u001b[39m y \u001b[38;5;241m/\u001b[39m y_norm\n\u001b[0;32m    138\u001b[0m zeros \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mzeros((b, \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'linear_hyperbolic_3' (type LinearHyperbolic).\n\n{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [2708,1] vs. shape[1] = [1,2708,1432] [Op:ConcatV2] name: concat\n\nCall arguments received by layer 'linear_hyperbolic_3' (type LinearHyperbolic):\n  • inputs=tf.Tensor(shape=(2708, 1433), dtype=float32)"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    hgcn((X, graph_tf))\n",
    "    #grads = tape.gradient(loss_value, self.embedding.trainable_weights)\n",
    "    #optimizer.apply_gradients(zip(grads, self.embedding.trainable_weights))\n",
    "\n",
    "    #if step % 100 == 0:\n",
    "    #    log.info(\"Training loss (for one batch) at step %d: %.4f\"\n",
    "    #        % (step, float(loss_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4663163",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    hgcn((X, graph.a))\n",
    "    #grads = tape.gradient(loss_value, self.embedding.trainable_weights)\n",
    "    #optimizer.apply_gradients(zip(grads, self.embedding.trainable_weights))\n",
    "\n",
    "    #if step % 100 == 0:\n",
    "    #    log.info(\"Training loss (for one batch) at step %d: %.4f\"\n",
    "    #        % (step, float(loss_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c078f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
